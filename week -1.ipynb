{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJLO9wNDfXgHOqju7i0YHN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamyaSasi1010/Cold-email-generator/blob/master/week%20-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzfN3raJqAV7",
        "outputId": "a7577de9-40ac-43f6-e689-fcb1fb73dd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/farzadnekouei/trash-type-image-dataset\n",
            "License(s): unknown\n",
            "trash-type-image-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Found 2527 files belonging to 6 classes.\n",
            "Using 2022 files for training.\n",
            "Found 2527 files belonging to 6 classes.\n",
            "Using 505 files for validation.\n",
            "Class names: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
            "Number of classes: 6\n",
            "Train batches: 64\n",
            "Validation batches: 8\n",
            "Test batches: 8\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "kaggle_api_key = {\n",
        "    \"username\": \"ramyas10\",\n",
        "    \"key\": \"8552f43d41f0b89da45e5a3f0dec3675\"\n",
        "}\n",
        "\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n",
        "    json.dump(kaggle_api_key, f)\n",
        "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
        "\n",
        "!kaggle datasets download -d farzadnekouei/trash-type-image-dataset\n",
        "\n",
        "with zipfile.ZipFile(\"trash-type-image-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"TrashType_Image_Dataset\")\n",
        "\n",
        "dataset_dir = r\"TrashType_Image_Dataset/TrashType_Image_Dataset\"\n",
        "image_size = (124, 124)\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "\n",
        "test_ds = val_ds.take(val_batches // 2)\n",
        "val_dat = val_ds.skip(val_batches // 2)\n",
        "test_ds_eval = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Class names:\", train_ds.class_names)\n",
        "print(\"Number of classes:\", len(train_ds.class_names))\n",
        "print(\"Train batches:\", tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(\"Validation batches:\", tf.data.experimental.cardinality(val_dat).numpy())\n",
        "print(\"Test batches:\", tf.data.experimental.cardinality(test_ds).numpy())\n"
      ]
    }
  ]
}